name: sls remove action
description: Reusable sls remove

inputs:
  app:
    description: 'Server application name'
    required: true
  auth0-audience:
    description: 'Auth0 Audience'
    required: true
  auth0-client-id:
    description: 'Auth0 Client ID'
    required: true
  auth0-shared-secret:
    description: 'Auth0 Shared Secret'
    required: true
  aws-access-key-id:
    description: 'AWS Access Key ID'
    required: true
  aws-acm-certificate-arn:
    description: 'Arn for AWS ACM Certificate'
    required: true
  aws-region:
    description: 'AWS Region'
    required: true
  aws-secret-access-key:
    description: 'AWS Secret Access Key'
    required: true
  environment-name:
    description: 'The environment name'
    required: true
  hostname:
    description: 'Hostname'
    required: true
  sentry-dsn-api:
    description: 'Sentry DSN for the API'
    required: true
  sentry-dsn-public-api:
    description: 'Sentry DSN for the Public API'
    required: true
  sentry-dsn-handlers:
    description: 'Sentry DSN for handlers other than the API'
    required: true
  ses-region:
    description: 'AWS SES Region'
    required: true
  slack-webhook:
    description: 'Slack webhook URL'
    required: false
  sls-stage:
    description: 'Serverless Stage'
    required: false

runs:
  using: 'composite'
  steps:
    - name: Setup
      id: setup
      uses: ./.github/actions/setup-environment
      with:
        environment-name: Branch
    - name: Check PR Number
      if: ${{ github.event.inputs.pr-number }}
      uses: ./.github/actions/is-number
      with:
        number: ${{ github.event.inputs.pr-number }}
    - name: Rebuild dependencies
      shell: bash
      run: yarn rebuild
    - name: Build type definitions
      shell: bash
      run: yarn build:typecheck
    - name: Clean S3 Files Bucket
      if: ${{ env.SLS_STAGE != 'production' && env.SLS_STAGE != 'dev' }}
      shell: bash
      run: |
        # Function to clean S3 bucket
        cleanup_s3_bucket() {
          local bucket_name="asap-hub-${SLS_STAGE}-files"

          echo "Checking if bucket $bucket_name exists..."
          if aws s3api head-bucket --bucket "$bucket_name" 2>/dev/null; then
            echo "Bucket $bucket_name exists. Cleaning up..."

            # Remove all current objects
            echo "Removing all objects..."
            aws s3 rm "s3://$bucket_name" --recursive || echo "No objects to remove or already empty"

            # Abort incomplete multipart uploads
            echo "Aborting incomplete multipart uploads..."
            aws s3api list-multipart-uploads --bucket "$bucket_name" --output json 2>/dev/null | \
            jq -r '.Uploads[]? | "\(.Key)\t\(.UploadId)"' | \
            while IFS=$'\t' read -r key upload_id; do
              if [ ! -z "$key" ] && [ ! -z "$upload_id" ]; then
                echo "Aborting multipart upload: $key ($upload_id)"
                aws s3api abort-multipart-upload --bucket "$bucket_name" --key "$key" --upload-id "$upload_id" || true
              fi
            done

            # Verify bucket is empty
            echo "Verifying bucket is empty..."
            local object_count=$(aws s3 ls "s3://$bucket_name" --recursive | wc -l)
            if [ "$object_count" -eq 0 ]; then
              echo "Bucket $bucket_name is now empty and ready for deletion"
            else
              echo "⚠️ Warning: Bucket still contains $object_count objects"
              aws s3 ls "s3://$bucket_name" --recursive
            fi
          else
            echo "Bucket $bucket_name does not exist, skipping cleanup"
          fi
        }

        # Call the cleanup function
        cleanup_s3_bucket
      env:
        AWS_ACCESS_KEY_ID: ${{ inputs.aws-access-key-id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws-secret-access-key }}
        AWS_REGION: ${{ inputs.aws-region }}
        SLS_STAGE: ${{ inputs.sls-stage }}
    - name: Remove CF Stack
      if: ${{ env.SLS_STAGE != 'production' && env.SLS_STAGE != 'dev' }}
      shell: bash
      run: |
        # Disable the 'exit immediately' flag which is set by default
        set +e
        INFO=$(yarn workspace @asap-hub/${{ inputs.app }} run pnpify sls info 2>&1)
        echo $INFO
        # Skip if the stack does not exist
        if [[ $INFO != *"does not exist"* ]]; then
          yarn workspace @asap-hub/${{ inputs.app }} run pnpify sls remove --verbose
        fi
      env:
        ACTIVE_CAMPAIGN_ACCOUNT: 'n-a'
        ACTIVE_CAMPAIGN_TOKEN: 'n-a'
        ALGOLIA_INDEX: 'n-a'
        AUTH0_AUDIENCE: ${{ inputs.auth0-audience }}
        AUTH0_CLIENT_ID: ${{ inputs.auth0-client-id }}
        AUTH0_SHARED_SECRET: ${{ inputs.auth0-shared-secret }}
        AWS_ACCESS_KEY_ID: ${{ inputs.aws-access-key-id }}
        AWS_ACM_CERTIFICATE_ARN: ${{ inputs.aws-acm-certificate-arn }}
        AWS_REGION: ${{ inputs.aws-region }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws-secret-access-key }}
        CONTENTFUL_ACCESS_TOKEN: 'n-a'
        CONTENTFUL_ENV: 'n-a'
        CONTENTFUL_MANAGEMENT_ACCESS_TOKEN: 'n-a'
        CONTENTFUL_PREVIEW_ACCESS_TOKEN: 'n-a'
        CONTENTFUL_SPACE_ID: 'n-a'
        CONTENTFUL_WEBHOOK_AUTHENTICATION_TOKEN: 'n-a'
        CURRENT_REVISION: ${{ github.sha }}
        HOSTNAME: ${{ inputs.hostname }}
        NODE_ENV: 'production'
        NODE_OPTIONS: '--max-old-space-size=8192'
        OPENAI_API_KEY: 'n-a'
        POSTMARK_SERVER_TOKEN: 'n-a'
        SENTRY_DSN_API: ${{ inputs.sentry-dsn-api }}
        SENTRY_DSN_PUBLIC_API: ${{ inputs.sentry-dsn-public-api }}
        SENTRY_DSN_HANDLERS: ${{ inputs.sentry-dsn-handlers }}
        SES_REGION: ${{ inputs.ses-region }}
        SLACK_WEBHOOK: ${{ inputs.slack-webhook }}
        SLS_STAGE: ${{ inputs.sls-stage }}
        AWS_OS_USERNAME: 'n-a'
        AWS_OS_PASSWORD: 'n-a'
